---
categories:
  - python
date: 2023-12-01 19:51:26
tags:
  - 机器学习
  - python
title: 使用 bert-vits2 进行训练/推理的踩坑记录
---

# 引言

阅读本文的一大前提是您可以看懂 [Bert-vits2](https://github.com/fishaudio/Bert-VITS2) 项目中的部分源码，至少对训练相关代码需要有基础的理解

本文不提供一键脚本或整合包，仅提供基础流程和部分坑点及部分数据预处理脚本。
<Note type="warning">
本文只适用于 2.3 final 版本，中文特化版建议等待更新
</Note>

# 训练流程

## 音频重采样

此部分可能遇到的问题:

### 采样率应该使用多少?

除非你能自行训练底模或者在无需底模的情况下训练，否则保持默认的`44100`

### 重采样过于缓慢

此部分使用 CPU 进行相关操作，部分 GPU 云计算平台在无卡模式下(或者常规模式下) CPU 性能比桌面级平台要慢很多，建议在本地预处理后再上传到 GPU 云平台

### 重采样不开始或长时间无变化

在没有日志的情况下此问题无解。建议检查是否重采样时出现了内存不足的问题。

## 训练集预处理

### filelist生成

本文不考虑训练集以何种方式进行收集，仅提供预处理方法。

对于不带有标注的语音文件，请自行手打标注或使用`whisper`等进行处理，建议参考[VITS-fast-fine-tuning项目](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/scripts/short_audio_transcribe.py)进行编写

对于带有lab格式标注的语音文件(例如[AI-Hobbyist Genshin_Datasets](https://github.com/AI-Hobbyist/Genshin_Datasets))，可参照下列py文件自行生成 filelist:

```python
import os

path = 'Data/audios'  # 训练集存放位置，此文件夹下应有wavs(已重采样音频)和text(lab格式标注文件)
character = "角色名"  # 角色名，可使用中文
lang = "ZH"  # 训练集语言
for root, dirs, files in os.walk(path):
    for file in files:
        if '.wav' not in file:
            continue
        wav_path = f"{path}/wavs/{file}"
        text_path = f"{path}/text/{file.replace('.wav', '.lab')}"
        with open(text_path, 'r', encoding='utf-8') as lab:
            lab_line = lab.readline().strip()
            if 'color' in lab_line or '{' in lab_line:
                continue
            l_string = f"{wav_path}|{character}|{lang}|{lab_line}"
            with open(f'filelists/{character}.list', 'a+', encoding='utf-8') as f:
                f.write(l_string + '\n')
```

### preprocess_text

对于preprocess_text的配置可能遇到的问题：

#### val_per_spk设置为多少?

合理即可。例如1500条数据集设置为4就不太合理。不建议设置太大。

#### 要开启数据清洗吗?

开。数据清洗可以预处理掉明显不符合格式/缺项漏项/文本包含特殊标记的训练集，便于训练使用。

如果训练集是以特殊方法从游戏或应用中提取的，务必开启数据清洗，否则可能出现类似于`{NICKNAME}`等标记混入训练集之中，影响后续操作

## bert生成

本部分没什么特别重要的问题，只需要注意：

1. 现版本无需自行下载模型，bert_gen的时候会自动下载
2. 设备优先选GPU，有`cuda`或者`mps`且能跑起来就优先用，尽量别用`cpu`
3. 无需特别关注并行数，一般默认值就可以了

关于镜像选择：

- `huggingface`：国外服务器(例如AWS海外)的用这个
- `openi`：国内服务器务必使用，即使有网络加速也不要用`huggingface`，能慢到怀疑人生

## 训练config

此处坑点较多，且对训练有一定影响，提供部分常用配置：

- `eval_interval`：控制模型保存和tensorboard中audio预览的生成频率，过低会影响训练速度，建议根据训练集动态调整
- `seed`：随机种子，选个幸运数字就行，对实际效果影响不大
- `epochs`：最大训练轮数，建议保持默认
- `batch_size`：控制模型训练速度和优化性能，一般设置为显存的50%(例如3090 24GB设置为12)，但部分专业卡或者配置可以和显存对等(例如V100 32GB设置为32)
  建议非专业卡按照50%设置，如果训练时显存占用不满就逐步调高，直到显存占用稳定在95%以上
- `bf16_run`：使用BF16进行训练/推理。需要安培架构或更新的显卡，如果支持建议使用。开启此选项时，`batch_size`的50%不适用，请自行调整
- `n_speakers`：调整为实际说话人数即可。设置过大可能影响训练速度与显存占用

对于部分机器学习常见参数不做解释，请自行查询相关参数作用

## 开始训练

### 需要使用底模吗?

没有训练经验或者数据集不够大的(我认为至少总长度不能少于1小时)，务必使用底模进行 finetune 训练，否则可能出现训练不正常/生成电音/效果奇差等问题

使用底模需要填写`openi_token`，请注意在mirror部分提前填写

### 训练应在何时结束?

没有准确答案。如果数据集较大建议在6000步后使用 TensorBoard 的 Audios 查看验证集效果。数据集较小则建议每200步查看一次。

## 如果你还没有可靠的GPU资源

那么我建议你使用 AWS 的 EC2 机器学习加速计算实例，`Tesla T4`可以适用大部分的初步机器学习需求，例如本文的`Bert-VITS2`
现在注册[亚马逊云科技](https://www.amazonaws.cn/?sc_channel=seo&sc_campaign=blog921&trk=82e7324f-8d11-415c-a27c-4aca0d749cf9)账户可以享受[12个月免费套餐](https://aws.amazon.com/cn/free/)，其中包括 Amazon EC2 云服务器、S3 云储存、Cloudfront CDN等多种热门产品。
为节省时间，此处省去注册账号的过程，在注册后进入控制台，选择创建实例：
![](./bert-vits2/controller.png)
随后输入相关内容，实例选择`g4dn.xlarge`，系统选择`ubuntu 22.04LTS`，随后创建密钥对：
![](./bert-vits2/keys.png)
<Note type="info">
如果你有一定改写代码的能力，或许可以试试`Inf1`
</Note>
一切完成之后，启动实例，等待创建完成后使用SSH连接到终端即可。
<Note type="info">
`g4dn.xlarge`不属于免费套餐内容，使用时注意余额
</Note>
